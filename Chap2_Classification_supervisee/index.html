<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Nicolas OUDART" /><link rel="canonical" href="https://nicoudart.github.io/UVSQ_LSSI633_data_science/Chap2_Classification_supervisee/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>II. Classification supervisée - UVSQ_LSSI633_data_science</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "II. Classification supervis\u00e9e";
        var mkdocs_page_input_path = "Chap2_Classification_supervisee.md";
        var mkdocs_page_url = "/UVSQ_LSSI633_data_science/Chap2_Classification_supervisee/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> UVSQ_LSSI633_data_science
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Accueil</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../Chap1_Introduction/">I. Introduction</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">II. Classification supervisée</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#probleme-de-classification-supervisee">Problème de classification supervisée</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#les-differents-types-de-classification">Les différents types de classification</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#binaire">Binaire</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#multi-classe">Multi-classe</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#multi-etiquettes">Multi-étiquettes</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exemple-de-probleme">Exemple de problème</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#mesures-de-performance">Mesures de performance</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#matrice-de-confusion">Matrice de confusion</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exactitude">Exactitude</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#precision-rappel-et-score-f1">Précision-rappel et score F1</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#courbe-roc">Courbe ROC</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#methodes-de-base">Méthodes de base</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#decision-bayesienne">Décision Bayesienne</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#principe">Principe</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#frontiere-de-decision-et-erreur">Frontière de décision et erreur</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#choix-du-modele">Choix du modèle</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#maximum-de-vraisemblance">Maximum de vraisemblance</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#implementation-scipy">Implémentation Scipy</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#implementation-scikit-learn">Implémentation Scikit-Learn</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#application-a-notre-exemple">Application à notre exemple</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#remarques">Remarques</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#k-plus-proches-voisins">K Plus Proches Voisins</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#principe_1">Principe</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#choix-de-la-distance">Choix de la distance</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#choix-du-parametre-k">Choix du paramètre K</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#implementation-scikit-learn_1">Implémentation Scikit-Learn</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#outils-de-visualisation-mlxtend">Outils de visualisation MLxtend</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#application-a-notre-exemple_1">Application à notre exemple</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#remarques_1">Remarques</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#perceptron-multicouche">Perceptron multicouche</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#perceptron-un-neurone-artificiel">Perceptron : un neurone artificiel</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#perceptron-multicouche-un-reseau-de-neurones-artificiels">Perceptron multicouche : un réseau de neurones artificiels</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#retropropagation-du-gradient">Retropropagation du gradient</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#choix-des-hyperparametres">Choix des hyperparamètres</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#implementation-scikit-learn_2">Implémentation Scikit-Learn</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#application-a-notre-exemple_2">Application à notre exemple</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#remarques_2">Remarques</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../Chap3_Regression/">III. Régression</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../Chap4_Partitionnement/">IV. Partitionnement</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">UVSQ_LSSI633_data_science</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">II. Classification supervisée</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="chapitre-ii-classification-supervisee">Chapitre II : Classification supervisée</h1>
<p>Ce chapitre est une introduction à la classification supervisée : principe, mesures de performances et méthodes de base.</p>
<p><img alt="En-tête chapitre II" src="../img/Chap2_header.png" /></p>
<hr />
<h2 id="probleme-de-classification-supervisee">Problème de classification supervisée</h2>
<p>Comme mentionné lors du Chapitre I, par "<strong>classifier</strong>" on entend associer une réalisation d'une variable <strong>quantitative discrète</strong> ou <strong>qualitative</strong> à un individu (labels), à partir des réalisations d'autres variables (features).
On appelle ces labels des "<strong>classes</strong>".</p>
<p>On parlera ici de "classification supervisée" car on va entrainer un modèle (aussi appelé "classifieur") à associer une classe à des individus, en se basant sur des données déjà labélisées.
Il s'agit donc bien d'un <strong>apprentissage supervisé</strong>.</p>
<p>L'idée est que le classifieur soit ensuite capable de <strong>généraliser</strong> : prédire la "classe" d'un nouvel individu.</p>
<h3 id="les-differents-types-de-classification">Les différents types de classification</h3>
<p>Plutôt que de parler de "la" classification, on devrait par "des" classifications, car il existe plusieurs types de problèmes de classification.</p>
<p>Nous allons donc commencer par parler des différents types de classification, en illustrant avec un exemple : reconnaitre sur une photo un instrument de musique breton.</p>
<h4 id="binaire">Binaire</h4>
<p>Le type de classification le plus basique, et pour lequel tous les modèles de classification peuvent être entrainés, est la <strong>classification binaire</strong>.</p>
<p>Comme son nom l'indique, l'idée est simplement de résoudre un problème où l'on veut séparer les individus en <strong>2 classes</strong>.</p>
<p>Il peut s'agir de prédire l'appartenance à 2 classes exclusives dans un cas où il n'y a que 2 labels possibles, par exemple : "L'instrument sur la photo est-il une bombarde ou un biniou ?".
Ou alors il peut s'agir de prédire l'appartenance ou la non appartenance à une classe parmi d'autres, par exemple : "L'instrument sur la photo est-il une bombarde ou un autre instrument ?".</p>
<p><img alt="Classification binaire" src="../img/Chap2_classification_binaire.png" /></p>
<p>Beaucoup des méthodes et des critères de performances qui sont présentées dans ce cours ont d'abord été définis pour des problèmes binaires, avant d'être généralisés.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Nota Bene :</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">En général, un classifieur binaire ne retourne pas directement une prédiction de la classe de l'individu, mais une <strong>probabilité d'appartenance à la classe</strong> : un score entre 0 et 1.</td>
</tr>
<tr>
<td style="text-align: left;">Il faut alors placer un <strong>seuil</strong> sur cette probabilité pour choisir si l'individu appartient à la classe ou non (souvent 0.5 par défaut).</td>
</tr>
<tr>
<td style="text-align: left;">On appelle ce seuil <strong>frontière de décision</strong>.</td>
</tr>
<tr>
<td style="text-align: left;">Les implémentations Scikit-Learn des méthodes de classification peuvent souvent retourner soit directement la classe prédite, soit la probabilité d'appartenance à la classe.</td>
</tr>
</tbody>
</table>
<h4 id="multi-classe">Multi-classe</h4>
<p>Si on veut classer des individus dans <strong>plus de 2 classes</strong>, on va parler de <strong>classification multi-classe</strong>.</p>
<p>Par exemple, "L'instrument sur la photo est-il une bombarde ou un biniou" est un problème de classification binaire, alors que "L'instrument sur la photo est-il une bombarde, un biniou ou un tambour ?" est un problème de classification multi-classe.</p>
<p>Or, si toutes les méthodes sont capables de réaliser une classification binaires, toutes ne sont pas capables de réaliser une classification multi-classe.</p>
<p>Pour contourner ce problème, on va ramener ce problème à de <strong>multiples classifications binaires</strong>, avec une stratégie pour choisir la prédiction à retourner :</p>
<ul>
<li><strong>One-versus-All</strong> : on entraine un classifieur binaire par classe, et la classe prédite pour un individu donné sera celle dont le classifieur aura retourné la probabilité la plus élevée.</li>
</ul>
<p><img alt="One-versus-All" src="../img/Chap2_One_vs_All.png" /></p>
<ul>
<li><strong>One-versus-One</strong> : on entraine un classifieur pour chaque couple de classes possible, et la classe prédite est celle qui aura gagné le plus de "duels" parmi les sorties des différents classifieurs.</li>
</ul>
<p><img alt="One-versus-One" src="../img/Chap2_One_vs_One.png" /></p>
<p>Pour <span class="arithmatex">\(N\)</span> classes, la stratégie "One-versus-One" implique d'entrainer <span class="arithmatex">\(N(N-1)/2\)</span> classifieurs, là où la stratégie "One-versus-All" n'a besoin d'en entrainer que <span class="arithmatex">\(N\)</span>.
Mais chaque modèle est entrainé sur un plus petit jeu de données pour la méthode "one-versus-one" que pour la méthode "one-versus-all"</p>
<p><strong>Le choix de stratégie dépendra donc de l'application</strong>.</p>
<p>Les méthodes disponibles sous Scikit-Learn choisissent une stratégie par défaut, mais il est possible de la modifier.</p>
<h4 id="multi-etiquettes">Multi-étiquettes</h4>
<p>Dans les types de classification précédents, on ne pouvait associer qu'une seule classe à un individu.</p>
<p>Cependant, pour certains problèmes il est possible qu'<strong>un individu puisse faire partie de plusieurs classes à la fois</strong>.</p>
<p>Par exemple, si le problème est "Quel instrument est sur cette photo ?", et que la photo contient une bombarde et un biniou, alors le morceau appartient à la fois à la classe "bombarde" et à la classe "biniou".</p>
<p>Certaines méthodes implémentées dans Scikit-Learn accèptent une matrices de labels en entrainement au lieu d'un vecteur, et d'autres non.
Il faut donc vérifier si la méthode que vous voulez utiliser supporte bien la classification multi-étiquettes.</p>
<p>Si un classifieur est multi-étiquettes, et que chaque étiquette est multi-classe, on dira le classifieur "<strong>multi-sorties</strong>".</p>
<h3 id="exemple-de-probleme">Exemple de problème</h3>
<p><strong>Pourquoi est-on capables de reconnaitre le son d'un instrument de musique d'un autre ?</strong></p>
<p>Lorsqu'un instrument joue une note, le son émit ne contient jamais qu'une seule fréquence.
Il est en réalité constitué d'une "fréquence fondamentale" (la note que l'on veut jouer), et des "harmoniques" (des fréquences multiples de la fondamentale).</p>
<p>Pour une même note jouée, suivant l'instrument, les harmoniques n'auront pas la même amplitude comparée à la fondamentale.
C'est ce que l'on appelle le "timbre" de l'instrument.
Lorsque nous écoutons de la musique, et que nous reconnaissons le son d'un instrument, c'est grâce à son timbre.</p>
<p>Voici 3 exemples de spectres issus d'enregistrements d'une flute, d'un hautbois et d'une trompette jouant un La (440 Hz) :</p>
<p><img alt="Spectres des 3 instruments" src="../img/Chap2_spectres_instruments.png" /></p>
<p>On voit nettement la différence de timbre entre les 3 instruments.</p>
<p>D'où l'idée suivante : <strong>peut-on entrainer un modèle à reconnaitre un instrument à partir d'un enregistrement ?</strong></p>
<p>Voici un jeu de données au format CSV, collectées à partir de milliers d'enregistrements d'une flute, d'un hautbois et d'une trompette jouant un La (440 Hz) : <a href="https://github.com/NicOudart/UVSQ_LSSI633_data_science/tree/master/datasets/Chap2_instruments_dataset.csv">Chap2_instruments_dataset</a></p>
<p>Le tableau de données qu'il contient est de la forme suivante :</p>
<table>
<thead>
<tr>
<th style="text-align: center;">instrument</th>
<th style="text-align: center;">harmo1</th>
<th style="text-align: center;">harmo2</th>
<th style="text-align: center;">harmo3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">oboe</td>
<td style="text-align: center;">11.842</td>
<td style="text-align: center;">11.58</td>
<td style="text-align: center;">10.28</td>
</tr>
<tr>
<td style="text-align: center;">flute</td>
<td style="text-align: center;">-17.083</td>
<td style="text-align: center;">-17.384</td>
<td style="text-align: center;">-21.496</td>
</tr>
<tr>
<td style="text-align: center;">trumpet</td>
<td style="text-align: center;">-8.152</td>
<td style="text-align: center;">-24.089</td>
<td style="text-align: center;">-23.813</td>
</tr>
<tr>
<td style="text-align: center;">oboe</td>
<td style="text-align: center;">9.381</td>
<td style="text-align: center;">12.434</td>
<td style="text-align: center;">11.905</td>
</tr>
<tr>
<td style="text-align: center;">oboe</td>
<td style="text-align: center;">-1.217</td>
<td style="text-align: center;">2.082</td>
<td style="text-align: center;">16.275</td>
</tr>
<tr>
<td style="text-align: center;">trumpet</td>
<td style="text-align: center;">-3.294</td>
<td style="text-align: center;">-13.812</td>
<td style="text-align: center;">-17.934</td>
</tr>
<tr>
<td style="text-align: center;">trumpet</td>
<td style="text-align: center;">-4.118</td>
<td style="text-align: center;">-13.485</td>
<td style="text-align: center;">-18.985</td>
</tr>
<tr>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
<tr>
<td style="text-align: center;">trumpet</td>
<td style="text-align: center;">-7.762</td>
<td style="text-align: center;">-5.934</td>
<td style="text-align: center;">-23.308</td>
</tr>
<tr>
<td style="text-align: center;">flute</td>
<td style="text-align: center;">-17.96</td>
<td style="text-align: center;">-19.406</td>
<td style="text-align: center;">-22.409</td>
</tr>
<tr>
<td style="text-align: center;">oboe</td>
<td style="text-align: center;">7.764</td>
<td style="text-align: center;">6.618</td>
<td style="text-align: center;">13.361</td>
</tr>
</tbody>
</table>
<p>Il contient pour chacun des 5612 enregistrements le nom de l'instrument, et l'amplitude en dB des 3 premières harmoniques relativement à la fondamentale.</p>
<p>Notre problème de classification sera le suivant : <strong>prédire l'instrument ayant joué un La à partir des amplitudes des 3 premières harmoniques</strong>.</p>
<p>Voyons d'abord si une telle classification est possible à partir de ces données.</p>
<p>Une fois le fichier CSV téléchargé, il peut être importé sous Python en tant que DataFrame Pandas à partir de son chemin d'accès "input_path" :</p>
<pre><code>import pandas as pd
df_dataset = pd.read_csv(input_path)
</code></pre>
<p>Il est possible avec Seaborn d'afficher ces données sous la forme d'une <strong>matrice de nuages de points</strong>, avec chaque classe d'une couleur différente.
Ce type de représentation permet de vérifier la séparabilité des différentes classes à partir des features sélectionnés.</p>
<p>Voici la commande Seaborn :</p>
<pre><code>import seaborn as sns
sns.pairplot(df_dataset,hue='instrument')
</code></pre>
<p>On obtient alors le graphique suivant :</p>
<p><img alt="Matrice de corrélations des 3 instruments" src="../img/Chap2_correlation_matrix_instruments.png" /></p>
<p>On observe que les classes "flute", "oboe" et "trumpet" sont plutôt bien séparables à partir des amplitudes des 3 premières harmoniques.
Vouloir entrainer un modèle à reconnaitre un de ces instruments à partir de ces données à donc du sens.</p>
<p><strong>Il est à noter que nous avons ici grandement simplifié le problème et sa résolution pour les besoins de ce cours.</strong>
<strong>Une vraie stratégie de validation pour optimiser les hyperparamètres et éviter le sur-apprentissage ne sera pas appliquée</strong>.</p>
<p><strong>L'idée est que nous verrons un exemple plus en détails en TP.</strong></p>
<h2 id="mesures-de-performance">Mesures de performance</h2>
<p>Nous allons passer en revue dans cette section les principaux indicateurs de performances applicables à tous les types de classification.</p>
<h3 id="matrice-de-confusion">Matrice de confusion</h3>
<p>Pour chaque classe <span class="arithmatex">\(C\)</span> possible, lorsqu'un classifieur réalise une prédiction sur un individu, il y a 4 possibilités :</p>
<ul>
<li>
<p>Le classifieur a prédit <span class="arithmatex">\(C\)</span>, et l'individu appartient bien à <span class="arithmatex">\(C\)</span> : c'est un <strong>vrai positif</strong> (noté TP).</p>
</li>
<li>
<p>Le classifieur a prédit <span class="arithmatex">\(C\)</span>, et l'individu n'appartient pas à <span class="arithmatex">\(C\)</span> : c'est un <strong>faux positif</strong> (noté FP).</p>
</li>
<li>
<p>Le classifieur n'a pas prédit <span class="arithmatex">\(C\)</span>, et l'individu n'appartient pas à <span class="arithmatex">\(C\)</span> : c'est un <strong>vrai négatif</strong> (noté TN).</p>
</li>
<li>
<p>Le classifieur n'a pas prédit <span class="arithmatex">\(C\)</span>, et l'individu appartient bien à <span class="arithmatex">\(C\)</span> : c'est un <strong>faux négatif</strong> (noté FN).</p>
</li>
</ul>
<p>Tous les scores de performance pour la classification que nous allons voir se basent sur le nombre de TP, FP, TN et FN obtenus par le modèle sur un jeu d'individus labélisé.</p>
<p>Les indicateurs brutes que sont le nombre de TP, FP, TN et FN sont en général mis sous la forme d'un tableau, que l'on appelle <strong>matrice de confusion</strong>.</p>
<p>Voici à quoi ressemble ce tableau pour une seule classe d'un problème multi-classe, ou pour un problème de classification binaire :</p>
<p><img alt="Matrice de confusion binaire" src="../img/Chap2_matrice_de_confusion_binaire.png" /></p>
<p>On peut également représenter les résultats d'une classification multi-classe pour toutes les classes sous la forme d'une matrice de confusion.</p>
<p>Voici un exemple pour 5 classes <span class="arithmatex">\(C_1\)</span>, <span class="arithmatex">\(C_2\)</span>, <span class="arithmatex">\(C_3\)</span>, <span class="arithmatex">\(C_4\)</span> et <span class="arithmatex">\(C_5\)</span> :</p>
<p><img alt="Matrice de confusion binaire" src="../img/Chap2_matrice_de_confusion_multiclasse.png" /></p>
<p>On peut alors lire ce tableau d'un point de vue général : la diagonale correspond aux vrais positifs à maximiser.
Mais on peut aussi le lire du point de vue d'une classe (<span class="arithmatex">\(C_3\)</span> dans notre illustration), et calculer les nombres de TP, FP, TN et FN correspondant.</p>
<p>La matrice de confusion est la représentation <strong>la plus exhaustive possible</strong> des performances d'un classifieur, mais elle est <strong>d'autant plus difficile à lire que le nombre de classes est grand</strong>.
Ceci peut rendre complexe la comparaison entre 2 classifieurs.</p>
<p>Pour cette raison, on va souvent utilisé des scores dérivés du tableau de confusion.</p>
<h3 id="exactitude">Exactitude</h3>
<p>Le score d'<strong>exactitude</strong> ("accuracy" en anglais) est le plus classique pour évaluer les performances d'un classifieur.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Définition</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">L'<strong>exactitude</strong> : est la taux d'individus classés correctement parmi tous les individus classés.</td>
</tr>
</tbody>
</table>
<p>Dans le cas d'une classification binaire, il s'agit donc de :</p>
<p><span class="arithmatex">\(\frac{TP+TN}{TP+FP+TN+FN}\)</span></p>
<p><img alt="Exactitude" src="../img/Chap2_exactitude.png" /></p>
<p>Dans le cas d'une classification multi-classe, il s'agira de la trace de la matrice de confusion divisée par le nombre total d'individus classés.</p>
<p>Si cet indicateur est intuitif et permet de condenser l'information en un score unique, il aura tendance à être biaisé s'il y a un fort déséquilibre entre classes.
En effet, comme on somme TP et TN, l'exactitude aura tendance à <strong>favoriser la classe majoritaire</strong>.</p>
<p>C'est pourquoi dans un cas déséquilibré, on préfèrera utiliser un duo de scores de performances : précision-rappel ou rappel-fausse alarme.</p>
<h3 id="precision-rappel-et-score-f1">Précision-rappel et score F1</h3>
<p>Si la classe considérée est <strong>majoritaire</strong>, ou si pour notre application nous préférons <strong>réduire les faux positifs</strong> quitte à augmenter les faux négatifs, on utilisera plutôt les indicateurs de <strong>précision</strong> et de <strong>rappel</strong>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Définitions</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">- La <strong>précision</strong> : est le taux d'individus attribués correctement à une classe parmi toutes les prédictions de cette classe.</td>
</tr>
<tr>
<td style="text-align: left;">- Le <strong>rappel</strong> ("sensibilité" ou "recall" en anglais) : est le taux d'individus attribués correctement à une classe tous les individus appartenant réellement à cette classe.</td>
</tr>
</tbody>
</table>
<p>Dans un cas binaire, il s'agit donc de :</p>
<ul>
<li>
<p>Précision : <span class="arithmatex">\(\frac{TP}{TP+FP}\)</span></p>
</li>
<li>
<p>Rappel : <span class="arithmatex">\(\frac{TP}{TP+FN}\)</span></p>
</li>
</ul>
<p><img alt="Précision-rappel" src="../img/Chap2_precision_rappel.png" /></p>
<p>Ces 2 scores sont <strong>antagonistes</strong> : on doit donc choisir un <strong>compromis</strong> entre les 2 suivant notre application.</p>
<p>Si on veut obtenir un compromis donnant une précision et un rappel similaires, on peut utiliser la moyenne harmonique de ces 2 scores :</p>
<p><span class="arithmatex">\(F_1 = \frac{2}{\frac{1}{precision}+\frac{1}{rappel}}\)</span></p>
<p>C'est ce que l'on appelle le <strong>score F1</strong>.</p>
<p>Mais si on veut trouver un compromis donnant une précision et un rappel en particulier, il faut utiliser une <strong>courbe précision-rappel</strong>.</p>
<p>L'idée est de faire varier le seuil de décision pour chaque classe, et d'afficher les compromis entre précision et rappel obtenus pour chaque seuil :</p>
<p><img alt="Courbe précision-rappel" src="../img/Chap2_courbe_precision_rappel.png" /></p>
<p>La ligne diagonale correspond à la performance théorique d'un classifieur aléatoire.</p>
<h3 id="courbe-roc">Courbe ROC</h3>
<p>Si la classe considérée est <strong>minoritaire</strong>, ou si pour notre application nous préférons <strong>réduire les faux négatifs</strong> quitte à augmenter les faux positifs, on utilisera plutôt les indicateurs de <strong>rappel</strong> et de <strong>fausse alarme</strong>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Définitions</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">- Le taux de <strong>fausse alarme</strong> : est taux d'individus attribués incorrectement à une classe parmi tous les individus n'appartenant pas à cette classe.</td>
</tr>
</tbody>
</table>
<p>Pour des raisons historiques, on appelle souvent dans ce contexte le rappel "<strong>taux de vrais positifs</strong>" (TPR) et le taux de fausse alarme "<strong>taux de faux positifs</strong>" (FPR).</p>
<p>Dans un cas binaire, il s'agit donc de :</p>
<ul>
<li>
<p>TPR : <span class="arithmatex">\(\frac{TP}{TP+FN}\)</span></p>
</li>
<li>
<p>FPR : <span class="arithmatex">\(\frac{FP}{FP+TN}\)</span></p>
</li>
</ul>
<p><img alt="ROC" src="../img/Chap2_ROC.png" /></p>
<p>Ces 2 scores sont également <strong>antagonistes</strong> : on doit donc aussi choisir un <strong>compromis</strong> entre les 2 suivant notre application.</p>
<p>Une fois encore, pour trouver un compromis donnant un TPR et un FPR en particulier, on peut tracer les compromis obtenus pour différents seuils de décision.</p>
<p>On appelle ce type de courbe "Reicever Operating Caracteristic" (ROC) :</p>
<p><img alt="ROC" src="../img/Chap2_ROC.png" /></p>
<p>Le nom étrange de cette courbe a une origine historique : elle aurait été inventée durant la 2nde guerre mondiale, dans le cadre de la classification binaire de signaux radar entre "avion ennemi" et "bruit".  </p>
<p><img alt="Courbe ROC" src="../img/Chap2_courbe_ROC.png" /></p>
<h2 id="methodes-de-base">Méthodes de base</h2>
<h3 id="decision-bayesienne">Décision Bayesienne</h3>
<p>La <strong>décision Bayesienne</strong>, aussi connue sous le nom de "classification Bayesienne naïve" est une méthode de classification se basant sur un <strong>modèle probabiliste</strong> des features, considérées <strong>indépendantes</strong>, et du <strong>théorème de Bayes</strong>.</p>
<h4 id="principe">Principe</h4>
<p>Imaginons que nous avons un problème de classification avec <span class="arithmatex">\(q\)</span> <strong>classes</strong> <span class="arithmatex">\(C_1\)</span>, <span class="arithmatex">\(C_2\)</span>, ..., <span class="arithmatex">\(C_q\)</span>.
Nous voulons prédire la classe à laquelle appartient un individu.</p>
<p>La probabilité de chaque classe <span class="arithmatex">\(i\)</span> notée <span class="arithmatex">\(p(C_i)\)</span>, aussi appelée "<strong>probabilité a priori</strong>".</p>
<p>On a <span class="arithmatex">\(\sum_{i=1}^{q} p(C_i) = 1\)</span> et on peut facilement estimer les différents <span class="arithmatex">\(p(C_i)\)</span> à partir du nombre d'occurences de <span class="arithmatex">\(C_i\)</span> dans les données divisée par la taille de la base de données.</p>
<p>En ne connaissant que les probabilités a priori de chaque classe, nous serions obligés de classer n'importe quel individu comme appartenant à la classe <span class="arithmatex">\(C_i\)</span> ayant le <span class="arithmatex">\(p(C_i)\)</span> le plus élevé.
Nous aurions alors un classifieur retournant toujours la même classe. 
Pas très utile...</p>
<p>Or, nous avons en réalité accès à plus d'informations : nos fameuses "features", dont nous voulons nous servir pour prédire la classe d'un individu.</p>
<p>Mettons que nous avons accès à une feature d'intérêt pour cette classification. 
On notera <span class="arithmatex">\(X\)</span> l'espace des <strong>observations</strong> associé.</p>
<p>Pour déterminer la classe d'un individu, on peut alors partir du principe suivant : choisir le <span class="arithmatex">\(C_i\)</span> tel que <span class="arithmatex">\(p(C_i \mid x)\)</span> <strong>soit maximal</strong>.
Nous expliquerons pourquoi dans la suite.</p>
<p>On nomme <span class="arithmatex">\(p(C_i \mid x)\)</span> "<strong>probabilités a posteriori</strong>".</p>
<p>D'après le <strong>théorème de Bayes</strong> :</p>
<p><span class="arithmatex">\(p(C_i \mid x) = \frac{p(x \mid C_i)p(C_i)}{p(x)}\)</span></p>
<p>avec <span class="arithmatex">\(p(x) = \sum_{i=1}^{q} p(x \mid C_i)p(C_i)\)</span></p>
<p>On nomme <span class="arithmatex">\(p(x)\)</span> la densité de "<strong>probabilité d'observation</strong>", et <span class="arithmatex">\(p(x \mid C_i)\)</span> la densité de "<strong>probabilité conditionnelle d'observation</strong>".</p>
<p>Toute la difficulté de la méthode est d'<strong>estimer</strong> <span class="arithmatex">\(p(x \mid C_i)\)</span>.
On va en général chercher à <strong>modéliser</strong> ces densités de probabilité conditionnelle.</p>
<p><img alt="Décision Bayesienne" src="../img/Chap2_decision_bayesienne.png" /></p>
<p><strong>NB :</strong> Il est à noter que rechercher la classe <span class="arithmatex">\(C_i\)</span> maximisant <span class="arithmatex">\(p(C_i \mid x)\)</span> <strong>est équivalent</strong> à rechercher <span class="arithmatex">\(C_i\)</span> maximisant <span class="arithmatex">\(p(x \mid C_i)p(C_i)\)</span>.
Il n'est donc en théorie pas utile de calculer <span class="arithmatex">\(p(x)\)</span> pour obtenir le classifieur.
Mais il est nécessaire d'avoir <span class="arithmatex">\(p(x)\)</span> pour obtenir des probabilités d'appartenance à une classe.</p>
<p><strong>Attention !</strong> En général, il y a des recouvrements entre les différentes densités de probabilité conditionnelle.
On ne peut alors pas obtenir classifieur parfait.
On cherchera juste le modèle permettant de minimiser les erreurs de classification. </p>
<p><strong>Cas particulier :</strong> Si tous les <span class="arithmatex">\(p(x \mid C_i)\)</span> sont égaux, alors la feature sélectionnée n'est pas pertinente pour la classification.</p>
<p>Ce principe est <strong>généralisable</strong> aux cas de classifications avec <span class="arithmatex">\(m\)</span> features d'espaces de probabilité <span class="arithmatex">\(X_1\)</span>, <span class="arithmatex">\(X_2\)</span>, ... <span class="arithmatex">\(X_m\)</span>.
On cherchera la classe <span class="arithmatex">\(C_i\)</span> qui maximise <span class="arithmatex">\(p(C_i) \prod_{j=1}^{m}p(x_j \mid C_i)\)</span>.</p>
<h4 id="frontiere-de-decision-et-erreur">Frontière de décision et erreur</h4>
<p>Comme nous l'avons expliqué précédemment, sauf cas particulier, on ne peut pas obtenir un classifieur parfait.</p>
<p>On va donc essayer d'établir des <strong>frontières de décision</strong> entre les classes : des intervalles de <span class="arithmatex">\(x\)</span> pour lesquels on attribura une classe.
Et nous recherchons même les frontières de décision optimales : celles qui minimisent le risque d'erreurs.</p>
<p>Prenons un cas simple de classification binaire entre 2 classes <span class="arithmatex">\(C_1\)</span> et <span class="arithmatex">\(C_2\)</span>.
Nous noterons <span class="arithmatex">\(x = D\)</span> la frontière de décision choisie.</p>
<p>On a alors 2 types d'erreurs de classification possibles : </p>
<ul>
<li>
<p>Classifier l'individu en <span class="arithmatex">\(C_1\)</span> alors qu'il appartient à <span class="arithmatex">\(C_2\)</span>.</p>
</li>
<li>
<p>Classifier l'individu en <span class="arithmatex">\(C_2\)</span> alors qu'il appartient à <span class="arithmatex">\(C_1\)</span>.</p>
</li>
</ul>
<p>Les probabilités d'erreurs associées sont <span class="arithmatex">\(\int_{-\infty}^{D} p(x \mid C_2)p(C_2) dx\)</span> et <span class="arithmatex">\(\int_{D}^{+\infty} p(x \mid C_1)p(C_1) dx\)</span>.</p>
<p>Elles correspondent aux aires représentées sur ce schéma : </p>
<p><img alt="Erreur décision Bayesienne" src="../img/Chap2_erreur_decision_bayesienne.png" /></p>
<p>Pour obtenir la frontière de décision optimale <span class="arithmatex">\(x = O\)</span>, on va chercher à minimiser la somme de ces erreurs.</p>
<p>L'aire entourée en vert correspond à ce que l'on appelle "l'<strong>erreur réductible</strong>" : c'est la portion de l'erreur totale que l'on peut réduire pour obtenir la frontière optimale.</p>
<p>On retrouve bien que :</p>
<ul>
<li>
<p>Si <span class="arithmatex">\(p(C_1 \mid x) &gt; p(C_2 \mid x)\)</span> alors on classifie l'individu comme appartenant à <span class="arithmatex">\(C_1\)</span>.</p>
</li>
<li>
<p>Si <span class="arithmatex">\(p(C_1 \mid x) &lt; p(C_2 \mid x)\)</span> alors on classifie l'individu comme appartenant à <span class="arithmatex">\(C_2\)</span>.</p>
</li>
</ul>
<p>On peut généraliser à <span class="arithmatex">\(q\)</span> classes : comme dit précédemment, pour obtenir les frontières de décision optimales, on choisi le <span class="arithmatex">\(C_i\)</span> tel que <span class="arithmatex">\(p(C_i \mid x)\)</span> <strong>soit maximal</strong>.</p>
<h4 id="choix-du-modele">Choix du modèle</h4>
<p>Comme nous l'avons expliqué, la décision Bayesienne nécessite un modèle des probabilités conditionnelles d'observation <span class="arithmatex">\(p(x \mid C_i)\)</span> pour chaque classe <span class="arithmatex">\(C_i\)</span>.</p>
<p>Pour ce faire, on <strong>ajuste une fonction de densité de probabilité</strong> pour chaque <span class="arithmatex">\(p(C_i \mid x)\)</span> à notre jeu d'entrainement.</p>
<p>Ceci implique donc 2 choix :</p>
<ul>
<li>
<p>Une <strong>fonction de densité de probabilité</strong>, ce qui implique de faire une <strong>hypothèse forte</strong> sur la distribution des observations pour chaque classe.</p>
</li>
<li>
<p>Une <strong>méthode d'ajustement de loi de probabilité</strong>.</p>
</li>
</ul>
<p>La fonction de densité de probabilité la plus classique est celle de la <strong>loi normale</strong> : </p>
<p><span class="arithmatex">\(f(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{- \frac{1}{2} (\frac{x - \mu}{\sigma})^2}\)</span></p>
<p>avec 2 paramètres à ajuster <span class="arithmatex">\(\mu\)</span> (la moyenne) et <span class="arithmatex">\(\sigma\)</span> (l'écart-type).</p>
<p>La méthode d'ajustement la plus classique pour la décision Bayesienne est celle du <strong>maximum de vraisemblance</strong>.
C'est elle que nous allons détailler.</p>
<h4 id="maximum-de-vraisemblance">Maximum de vraisemblance</h4>
<table>
<thead>
<tr>
<th style="text-align: left;">Définition</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Soit une loi de probabilité <span class="arithmatex">\(f(x,\theta)\)</span>, définie par des paramètres <span class="arithmatex">\(\theta\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">Pour un échantillon observé <span class="arithmatex">\((x_1,x_2,...,x_n)\)</span>, on nomme <strong>vraisemblance</strong> ("likelihood" en anglais) la probabilité que cet échantillon provienne d'un tirage de <span class="arithmatex">\(f(x,\theta)\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">Si les tirages sont indépendants, on peut exprimer la vraisemblance de la manière suivantes :</td>
</tr>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(L(x_1,x_2,...,x_n,\theta) = \prod_{k=1}^{n} f(x_k,\theta)\)</span></td>
</tr>
</tbody>
</table>
<p>La méthode du <strong>maximum de vraisemblance</strong> découle du fait que le modèle <span class="arithmatex">\(f\)</span> de paramètres <span class="arithmatex">\(\theta\)</span> représentant le mieux les observations est celui qui <strong>maximise</strong> la vraisemblance, c'est-à-dire <strong>la probabilité que l'échantillon provienne de cette loi</strong>.</p>
<p>L'idée est donc de rechercher les <span class="arithmatex">\(\theta\)</span> maximisant <span class="arithmatex">\(L(x_1,x_2,...,x_n,\theta)\)</span>.</p>
<p>Souvent, pour simplifier les calculs, on ne va pas rechercher le maximum de la vraisemblance, mais de la log-vraisemblance :</p>
<p><span class="arithmatex">\(log(L(x_1,x_2,...,x_n,\theta)) = \sum_{k=1}^{n} log(f(x_k,\theta))\)</span></p>
<p>En effet, rechercher les paramètres <span class="arithmatex">\(\theta\)</span> maximisant <span class="arithmatex">\(L\)</span> ou <span class="arithmatex">\(logL\)</span> est équivalent, et rechercher un maximum implique un calcul de dérivée, ce qui est plus simple pour des sommes que pour des produits.</p>
<p>On va donc pour chaque paramètre <span class="arithmatex">\(\theta_j\)</span> de <span class="arithmatex">\(\theta\)</span> la valeur qui vérifie <span class="arithmatex">\(\frac{\partial}{\partial{\theta_j}} \sum_{k=1}^{n} log(f(x_k,\theta)) = 0\)</span>.</p>
<p>Prenons l'exemple de la loi normale :</p>
<p><span class="arithmatex">\(f(x,\mu,\sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{- \frac{1}{2} (\frac{x - \mu}{\sigma})^2}\)</span></p>
<p>On cherchera alors les paramètres <span class="arithmatex">\(\theta = (\mu,\sigma)\)</span> vérifiant :</p>
<p><span class="arithmatex">\(\frac{\partial}{\partial{\theta}} \sum_{k=1}^{n} (-log(\sigma) - log(\sqrt{2 \pi}) - \frac{1}{2} (\frac{x - \mu}{\sigma})^2) = 0\)</span></p>
<p>soit <span class="arithmatex">\(\frac{\partial}{\partial{\theta}} (- n log(\sigma) - n log(\sqrt{2 \pi}) - \sum_{k=1}^{n} \frac{1}{2} (\frac{x - \mu}{\sigma})^2) = 0\)</span></p>
<p>soit pour chaque paramètre :</p>
<p><span class="arithmatex">\(\frac{\partial}{\partial{\mu}} (- n log(\sigma) - n log(\sqrt{2 \pi}) - \sum_{k=1}^{n} \frac{1}{2} (\frac{x - \mu}{\sigma})^2) = 0\)</span></p>
<p><span class="arithmatex">\(\frac{\partial}{\partial{\sigma}} (- n log(\sigma) - n log(\sqrt{2 \pi}) - \sum_{k=1}^{n} \frac{1}{2} (\frac{x - \mu}{\sigma})^2) = 0\)</span></p>
<p>On montre alors que les paramètres vérifiant ces équations sont :</p>
<p><span class="arithmatex">\(\mu = \frac{1}{n} \sum_{k=1}^{n} x_k\)</span> et <span class="arithmatex">\(\sigma^2 = \frac{1}{n} \sum_{k=1}^{n} (x_k - \mu)^2\)</span></p>
<p>Ce qui était attendu.</p>
<h4 id="implementation-scipy">Implémentation Scipy</h4>
<p>Afin de réaliser un ajustement de loi de probabilité, on peut utiliser la bibliothèque de calculs scientifiques Scipy, et en particulier son module de statistiques "scipy.stat".</p>
<p>Par exemple, pour un ajustement avec une loi normale, on pourra importer l'objet "norm" avec :</p>
<pre><code>from scipy.stats import norm
</code></pre>
<p>On peut alors ajuster une loi normale à un ensemble d'observations contenu dans un conteneur <code>x_obs</code>, et récupérer la moyenne <code>mu</code> et l'écart-type <code>sigma</code> avec :</p>
<pre><code>mu,sigma = norm.fit(x_obs)
</code></pre>
<p>Par défaut, la méthode du maximum de vraisemblance est utilisée.
Mais on peut également utiliser la "méthode des moments" (que nous ne présenterons pas dans ce cours), en ajoutant un paramètre <code>method = 'MM'</code> en entrée.</p>
<p>Une fois la loi normale ajustée, on a accès à la densité de probabilité <code>dp</code> associée à une réalisation <code>x</code> avec :</p>
<pre><code>dp = norm.pdf(x,mu,sigma)
</code></pre>
<p>Bien d'autres lois de probabilité sont disponibles dans le module "scipy.stats", et fonctionnent sur le même principe que "norm".</p>
<h4 id="implementation-scikit-learn">Implémentation Scikit-Learn</h4>
<p>Il est à noter qu'il existe aussi une implémentation de la classification Bayesienne dans Scikit-Learn, dans l'hypothèse de distributions des features suivant des lois normales.</p>
<p>Elle peut être importée avec :</p>
<pre><code>from sklearn.naive_bayes import GaussianNB
</code></pre>
<p>On doit alors créer un objet "GaussianNB" qui contiendra notre modèle, ici <code>bayes_classifier</code> :</p>
<pre><code>bayes_classifier = GaussianNB()
</code></pre>
<p>Il faut ensuite l'entrainer avec nos features et labels d'entrainement, nommés ici <code>feature_train</code> et <code>label_train</code> :</p>
<pre><code>bayes_classifier.fit(feature_train,label_train)
</code></pre>
<p>Et enfin, on peut réaliser une prédiction à partir de features de test, nommés <code>feature_test</code> :</p>
<pre><code>label_test = bayes_classifier.predict(feature_test)
</code></pre>
<p>Cette implémentation peut être pratique dans certains cas, mais elle ne permet pas de jouer sur les hyperparamètres suivants : la loi de probabilité et la méthode d'ajustement.
Une optimisation de ces hyperparamètres n'est donc pas possible avec Scikit-Learn.</p>
<h4 id="application-a-notre-exemple">Application à notre exemple</h4>
<p>Nous allons à présent appliquer la classification Bayesienne à notre problème exemple.</p>
<p>Afin de rendre la visualisation plus facile, nous allons simplifier le problème :</p>
<p>Mettons que nous voulons juste effectuer une classification binaire de nos enregistrements, entre les classes "flute" ou "trompette", en utilisant comme unique feature l'amplitude relative de la 1ère harmonique.</p>
<p>Pour ce faire, nous importons le fichier CSV depuis son chemin <code>input_path</code> sous la forme d'un DataFrame, et nous sélectionnons les variables et les individus qui nous intéressent :</p>
<pre><code>df_dataset = pd.read_csv(input_path)

df_dataset = df_dataset[['instrument','harmo1']]
df_dataset = df_dataset[(df_dataset['instrument']=='flute')|(df_dataset['instrument']=='trumpet')]
</code></pre>
<p>Nous diviserons ici nos données en un jeu d'entrainement (80%) et un jeu de test (20%), sous la forme de 2 DataFrames : </p>
<pre><code>df_train=df_dataset.sample(frac=0.8,random_state=0)
df_test=df_dataset.drop(df_train.index)
</code></pre>
<p>On peut alors tracer un histogramme de notre feature pour les données d'entrainement, en sépararant les 2 classes :</p>
<p><img alt="Histogramme de la 1ère harmonique pour la flute et la trompette" src="../img/Chap2_exemple_histogramme.png" /></p>
<p>On peut noter qu'il y a peu de recouvrement entre les 2 distributions, ce qui laisse entrevoir qu'il est possible d'entrainer un modèle à classifier ces données.</p>
<p>En 1ère approche, nous choisissons d'ajuster à ces 2 distributions des modèles de lois normales.
Il faudra se poser la question de la pertinence de ce choix.</p>
<p>Tout d'abord, nous allons séparer le jeu d'entrainement en 2 Series (DataFrame Pandas ne contenant qu'une colonnes) suivant si l'instrument est une flute ou une trompette :</p>
<pre><code>sr_harmo1_flute_train = df_train[df_train['instrument']=='flute']['harmo1']
sr_harmo1_trumpet_train = df_train[df_train['instrument']=='trumpet']['harmo1']
</code></pre>
<p>On peut alors réaliser nos 2 ajustements, et récupérer les paramètres <span class="arithmatex">\(mu\)</span> et <span class="arithmatex">\(\sigma\)</span> correspondants :</p>
<pre><code>from scipy.stats import norm

mu_harmo1_flute,sig_harmo1_flute = norm.fit(sr_harmo1_flute_train)
mu_harmo1_trumpet,sig_harmo1_trumpet = norm.fit(sr_harmo1_trumpet_train)
</code></pre>
<p>Maintenant que nous avons les paramètres de nos modèles, nous pouvons évaluer la densité des probabilités conditionnelles pour la classe "flute" et la classe "trompette".</p>
<p>Voici par exemple 301 évaluations pour des valeurs d'amplitude de la 1ère harmonique entre -30 et 0 dB :</p>
<pre><code>x_axis = np.linspace(-30,0,301)

proba_norm_flute = norm.pdf(x_axis,mean_harmo1_flute,sig_harmo1_flute)
proba_norm_trumpet = norm.pdf(x_axis,mean_harmo1_trumpet,sig_harmo1_trumpet)
</code></pre>
<p>Nous pouvons alors tracer les courbes correspondantes par-dessus notre histogramme (affiché en densité de probabilité) :</p>
<p><img alt="Probabilités conditionnelles" src="../img/Chap2_exemple_probabilites_conditionnelles.png" /></p>
<p>Si nos modèles ne paraissent pas complément inadaptés, on peut noter qu'ils ne capturent pas la légère asymétrie de nos distributions.
On pourrait donc se poser la question d'essayer d'autres lois de probabilités, asymétriques.</p>
<p>Continuons avec nos modèles pour les probabilités conditionnelles.</p>
<p>La prochaine étape est d'estimer la probabilité de chaque classe, à partir de leurs densités relatives :</p>
<pre><code>proba_flute = len(sr_harmo1_flute_train)/len(df_train)
proba_trumpet = len(sr_harmo1_trumpet_train)/len(df_train)
</code></pre>
<p>On peut alors utiliser estimer la densité de probabilité d'observation :</p>
<pre><code>proba_obs = proba_norm_flute*proba_flute + proba_norm_trumpet*proba_trumpet
</code></pre>
<p>Si nous l'affichons avec les histogrammes, nous pouvons vérifier qu'elle est bien cohérente avec la distribution des observations.</p>
<p><img alt="Probabilité d'observation" src="../img/Chap2_exemple_probabilite_observation.png" /></p>
<p>Enfin, nous pouvons calculer les probabilités a posteriori, en se basant sur la formule de Bayes :</p>
<pre><code>proba_bayes_flute = proba_norm_flute*proba_flute/proba_obs
proba_bayes_trumpet = proba_norm_trumpet*proba_trumpet/proba_obs
</code></pre>
<p>On peut alors afficher ces probabilités, et tracer la frontière de décision :</p>
<p><img alt="Probabilités a posteriori" src="../img/Chap2_exemple_probabilites_aposteriori.png" /></p>
<p>La frontière de décision se trouve à environ -13.16 dB : </p>
<ul>
<li>
<p>Si on mesure une 1ère harmonique ayant une amplitude inférieure, on classifiera l'instrument comme étant une flute.</p>
</li>
<li>
<p>Si on mesure une 1ère harmonique ayant une amplitude supérieure, on classifiera l'instrument comme étant une trompette.</p>
</li>
</ul>
<p>Comme nous l'avons mentionné précédemment, si la probabilité d'appartenance aux classes ne nous intéresse pas, nous pourrions juste comparer <span class="arithmatex">\(p(x \mid C = 'flute')p(C='flute')\)</span> et <span class="arithmatex">\(p(x \mid C = 'trumpet')p(C='trumpet')\)</span> pour classifier les observations. </p>
<p>Maintenant que nous avons vu le principe, on voudrait pouvoir ré-entrainer notre modèle afin d'optimiser les hyperparamètres, et réaliser des prédictions sur les jeux d'entrainement et de test, le tout de manière efficace.</p>
<p>Dans ce but, nous pouvons mettre notre classification binaire Bayesienne sous la forme d'une classe <code>binary_bayes</code> avec 2 méthodes <code>train</code> et <code>predict</code> pour l'entrainement et la prédiction.
Voici un exemple d'implémentation :</p>
<pre><code>class binary_bayes:

    def __init__(self,stat_model):

        self.stat_model = stat_model

        self.true_params = None
        self.false_params = None

        self.proba_true = None

    def train(self,x_true,x_false):

        self.true_params = self.stat_model.fit(x_true)
        self.false_params = self.stat_model.fit(x_false)

        len_true = len(x_true)
        len_false = len(x_false)
        self.proba_true = len_true/(len_true+len_false)

    def predict(self,x):

        proba_norm_true = self.stat_model.pdf(x,*self.true_params)
        proba_norm_false = self.stat_model.pdf(x,*self.false_params)

        proba_obs = proba_norm_true*self.proba_true + proba_norm_false*(1-self.proba_true)

        proba_bayes_true = proba_norm_true*self.proba_true/proba_obs

        return proba_bayes_true
</code></pre>
<p>On peut alors facilement définir un classifieur binaire "est-ce une flute ?" utilisant la loi normale telle qu'implémentée par Scipy :</p>
<pre><code>from scipy.stats import norm

is_a_flute = binary_bayes(norm)
</code></pre>
<p>Entrainer ce classifieur sur notre jeu d'entrainement :</p>
<pre><code>is_a_flute.train(sr_harmo1_flute_train,sr_harmo1_trumpet_train)
</code></pre>
<p>Et réaliser des prédictions sur nos données d'entrainement et de test :</p>
<pre><code>prediction_train = (is_a_flute.predict(df_train['harmo1']))

prediction_test = (is_a_flute.predict(df_test['harmo1']))
</code></pre>
<p>En partant du principe que nous positionnons la frontière de décision à une probabilité d'appartenance à classe "flute" de 0.5, nous pouvons obtenir les matrices de confusion en entrainement et en test avec les commandes suivantes :</p>
<pre><code>from sklearn.metrics import confusion_matrix

#Label encoding:
ground_truth_train = (df_train['instrument']=='flute').astype(int)
ground_truth_test = (df_test['instrument']=='flute').astype(int)

cm_train = confusion_matrix(ground_truth_train, prediction_train&gt;0.5)
cm_test = confusion_matrix(ground_truth_test, prediction_test&gt;0.5)
</code></pre>
<p>Voici les résultats en entrainement obtenus pour notre exemple :</p>
<p><img alt="Exemple de matrice de confusion" src="../img/Chap2_exemple_matrice_confusion.png" /></p>
<p>On observe que les performances du modèle sont très similaires entre les données d'entrainement et de test.
Ceci tend à montrer que l'on a pas de problème de sur-ajustement important, ce qui laisse présager des performances similaires en généralisation.</p>
<p>Il n'y a aucun faux positif, mais on a quelques faux négatifs : parfois notre modèle classifie des enregistrements de flutes comme n'étant pas des flutes.</p>
<p>Suivant les applications, on peut vouloir choisir une frontière de décision différente, pour diminuer le nombre de faux négatifs, au prix d'une augmentation du nombre de faux positifs.
Afin de voir les effets d'un tel choix, on tracer une courbe ROC à partir des probabilités prédites par notre modèle :</p>
<pre><code>from sklearn.metrics import roc_curve
fp_rate_train, tp_rate_train, thresholds_train = roc_curve(ground_truth_train, prediction_train)
fp_rate_test, tp_rate_test, thresholds_test = roc_curve(ground_truth_test, prediction_test)
</code></pre>
<h4 id="remarques">Remarques</h4>
<p>La méthode de la classification de Bayes a les <strong>avantages</strong> suivants :</p>
<ul>
<li>
<p>Elle fonctionne pour <strong>tous les types de classification et variables</strong>.</p>
</li>
<li>
<p>Elle est relativement <strong>simple</strong> à mettre en place, avec <strong>peu de paramètres</strong>.</p>
</li>
<li>
<p>Les décisions qu'elle prend sont complètement <strong>expliquées</strong> et <strong>interprétables</strong> : un humain peut les comprendre.</p>
</li>
</ul>
<p>Mais cette méthode a aussi les <strong>limites</strong> suivantes :</p>
<ul>
<li>
<p>Elle fait l'hypothèse de l'<strong>indépendance des variables</strong> entre elles, ce qui dans la pratique limite son application aux problèmes avec peu de features.</p>
</li>
<li>
<p>Elle fait une hypothèse forte sur la <strong>distribution des observations</strong> pour chaque variable. Il s'agit souvent d'une hypothèse de <strong>normalité</strong>.</p>
</li>
</ul>
<h3 id="k-plus-proches-voisins">K Plus Proches Voisins</h3>
<h4 id="principe_1">Principe</h4>
<p>La méthode de la classification Bayesienne que nous venons de voir avait pour désavantage de nécessiter une hypothèse sur la distribution des observations.</p>
<p>Dans cette section, nous allons présenter une méthode ne nécessitant aucun a priori sur les données : les <strong>K Plus Proches Voisin</strong>, aussi connue sous l'acronyme KPPV.</p>
<p>Les KPPV est une méthode dite de "lazy learning" : il n'y a pas de réel apprentissage préalable à la prédiction.
Le jeu de données d'apprentissage est <strong>stocké en mémoire</strong>, et utilisé au moment de la prédiction.</p>
<p>L'idée est la suivante : pour classer un nouvel individu, on va calculer sa <strong>distance aux <span class="arithmatex">\(k\)</span> individus les plus proches</strong> dans les données d'entrainement.
On attibura alors à l'individu la classe <strong>la plus représentée</strong> parmi ses <span class="arithmatex">\(k\)</span> "plus proches voisins".</p>
<p><img alt="K plus proches voisins" src="../img/Chap2_kppv.png" /></p>
<p>Prédire la classe d'un individu avec cette méthode implique :</p>
<p>(1) De mesurer la distance entre l'individu à classifier et <strong>tous les individus du jeu d'entrainement</strong>.
C'est ce que l'on appelle "l'approche brute". 
Et plus le jeu d'entrainement est grand, plus le temps de calcul sera long.
Pour cette raison, on choisi de stocker le jeu d'entrainement dans une <strong>structure de donnée la plus efficace à parcourir</strong> possible (exemple : KD-Tree).</p>
<p>(2) De choisir une <strong>mesure de distance</strong> adaptée au problème.</p>
<p>(3) De choisir le <strong>nombre de "plus proches voisins"</strong> à l'individu à considérer.</p>
<p>(4) De choisir de quelle manière on va affecter une classe à l'individu à partir de la classe de ses voisins : Un <strong>vote majoritaire</strong> ? 
S'il y a un gros déséquilibre entre classes, ce type de vote risque d'être biaisé.
On préférera alors un vote avec des <strong>poids différents</strong> suivant les classes.</p>
<h4 id="choix-de-la-distance">Choix de la distance</h4>
<p>Suivant le problème de classification auquel on est confronté, la "distance" entre 2 individus n'a pas le même sens.</p>
<p>En effet, on comprend bien qu'on utilisera pas les mêmes critères pour mesurer la distance entre 2 valeurs réelles, entre 2 images, ou entre 2 mots du dictionnaire.</p>
<p>D'où l'importance lorsqu'on utilise les KPPV de <strong>choisir une mesure de distance pertinente</strong> pour notre problème.</p>
<p>Parmi les mesures de distances classiques, on peut citer :</p>
<ul>
<li><strong>Distance Euclidienne</strong> : </li>
</ul>
<p>Si on veut mesurer la distance Euclidienne entre <span class="arithmatex">\(x\)</span> et <span class="arithmatex">\(y\)</span>, 2 vecteurs de dimension <span class="arithmatex">\(n\)</span> :</p>
<p><span class="arithmatex">\(D(x,y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\)</span></p>
<p>Il s'agit de la mesure de distance la plus connue et la plus utilisée.
Elle fonctionne bien lorsque l'on est confrontés à des valeurs réelles continues, normalisées, et avec une dimensionnalité faible.</p>
<p>Cette distance peut être vue comme la mesure de distance associée à la norme 2.</p>
<ul>
<li><strong>Distance de Manhattan</strong> :</li>
</ul>
<p>Si on veut mesurer la distance de Manhattan entre <span class="arithmatex">\(x\)</span> et <span class="arithmatex">\(y\)</span>, 2 vecteurs de dimension <span class="arithmatex">\(n\)</span> :</p>
<p><span class="arithmatex">\(D(x,y) = \sum_{i=1}^{n} \mid x_i - y_i \mid\)</span></p>
<p>Suivant l'espace des features de notre problème, tracer une "ligne droite" entre individus peut ne pas avoir de sens.
La distance de Manhattan est alors une alternative à la distance Euclidienne.</p>
<p>Cette distance peut être vue comme la mesure de distance associée à la norme 1.</p>
<ul>
<li><strong>Distance de Chebychev</strong> :</li>
</ul>
<p>Si on veut mesurer la distance de Chebychev entre <span class="arithmatex">\(x\)</span> et <span class="arithmatex">\(y\)</span>, 2 vecteurs de dimension <span class="arithmatex">\(n\)</span> :</p>
<p><span class="arithmatex">\(D(x,y) = max(\mid x_i - y_i \mid)\)</span></p>
<p>La distance de Chebychev est assez peu utilisée, car elle a des cas d'applications très spécifiques.
(Par exemple, les déplacements d'un roi sur un jeu d'échec ou les automates cellulaires).</p>
<p>Cette distance peut être vue comme la mesure de distance associée à la norme infinie.</p>
<ul>
<li><strong>Minkowski</strong> :</li>
</ul>
<p>Si on veut mesurer la distance de Minkowski entre <span class="arithmatex">\(x\)</span> et <span class="arithmatex">\(y\)</span>, 2 vecteurs de dimension <span class="arithmatex">\(n\)</span> :</p>
<p><span class="arithmatex">\(D(x,y) = (\sum_{i=1}^{n} \mid x_i - y_i \mid^p)^{1/p}\)</span></p>
<p>La distance de Minkowski est une généralisation des 3 distances précédentes.
En effet, on remarque que si <span class="arithmatex">\(p=1\)</span> elle revient à la distance de Manhattan, si <span class="arithmatex">\(p=2\)</span> elle revient à la distance Euclidienne, et si <span class="arithmatex">\(p\)</span> tend vers l'infini elle revient à la distance de Chebychev.</p>
<p>Elle permet donc de chercher un compromis entre ces différentes distances.</p>
<ul>
<li><strong>Hamming</strong> :</li>
</ul>
<p>Soit 2 chaines de caractères de même taille. 
La distance de Hamming entre ces 2 chaines est alors égale au nombre de positions pour lesquelles les caractères sont différents.</p>
<p>Cette mesure de distance est couramment utilisée lorsque l'on veut comparer des morceaux de textes caractère par caractère, ou de manière générale pour des données qualitatives.</p>
<ul>
<li><strong>Similarité cosinus</strong> :</li>
</ul>
<p>Si on veut mesurer la "similarité cosinus" entre 2 vecteurs <span class="arithmatex">\(x\)</span> et <span class="arithmatex">\(y\)</span> :</p>
<p><span class="arithmatex">\(D(x,y) = cos(\theta) = \frac{x.y}{\|x\| \|y\|}\)</span></p>
<p>Il s'agit du cosinus de l'angle entre les 2 vecteurs.</p>
<p>Cette mesure de distance est couramment utilisée lorsque l'on doit comparer des vecteurs de haute dimensionnalité, et où la norme du vecteur a peu d'importance.
Par exemple, c'est la mesure de distance privilégiée pour de la "fouille de texte" (comparaison mot à mot de chaines de caractère).</p>
<p><img alt="Exemples de distances" src="../img/Chap2_distances.png" /></p>
<p>La distance est donc un <strong>hyperparamètre à optimiser</strong> lorsque l'on utilise les KPPV.</p>
<h4 id="choix-du-parametre-k">Choix du paramètre K</h4>
<p>Il est évident que le choix de <span class="arithmatex">\(k\)</span> va avoir un impact sur les prédictions obtenues à partir des données d'entrainement.
C'est donc également un <strong>hyperparamètre à optimiser</strong>.</p>
<p>Pour choisir des valeurs de <span class="arithmatex">\(k\)</span> à tester, on peut partir des grands principes suivants :</p>
<ul>
<li>
<p>S'il y a un fort <strong>déséquilibre</strong> entre classes, il vaut mieux ne pas choisir un <span class="arithmatex">\(k\)</span> <strong>faible</strong>.</p>
</li>
<li>
<p>S'il y a beaucoup de <strong>recouvrement</strong> entre les classes, il vaut mieux choisir un <span class="arithmatex">\(k\)</span> <strong>élevé</strong>.</p>
</li>
<li>
<p>Avec un <span class="arithmatex">\(k\)</span> trop <strong>faible</strong> on risque le <strong>sur-apprentissage</strong>.</p>
</li>
<li>
<p>Avec un <span class="arithmatex">\(k\)</span> trop <strong>grand</strong> on risque le <strong>sous-apprentissage</strong>.</p>
</li>
</ul>
<p>Pour éviter les cas d'égalité, on va en général choisir une valeur de <span class="arithmatex">\(k\)</span> impaire.</p>
<h4 id="implementation-scikit-learn_1">Implémentation Scikit-Learn</h4>
<p>Il existe une implémentation Scikit-Learn de la méthode des KPPV.</p>
<p>Elle peut être importée avec :</p>
<pre><code>from sklearn.neighbors import KNeighborsClassifier
</code></pre>
<p>On peut ensuite initialiser un classifieur KPPV <code>knn</code> avec un objet "KNeighborsClassifier" de paramètre <code>k</code> correspondant au nombre de plus proches voisins :</p>
<pre><code>knn = KNeighborsClassifier(n_neighbors=k)
</code></pre>
<p>Pour donner le jeu d'entrainement (features avec <code>feature_train</code> et labels avec <code>label_train</code>) à ce classifieur, on utilise la méthode :</p>
<pre><code>knn.fit(feature_train,label_train)
</code></pre>
<p>On peut à présent réaliser des prédictions <code>label_test</code> à partir de features de test <code>feature_test</code> :</p>
<pre><code>label_test = knn.predict(feature_test)
</code></pre>
<p>Si on veut effectuer un test de notre classifieur sur un jeu de données labéliser, on peut obtenir un score d'exactitude avec la commande :</p>
<pre><code>knn.score(feature_test,label_test)
</code></pre>
<h4 id="outils-de-visualisation-mlxtend">Outils de visualisation MLxtend</h4>
<p>Pour afficher les frontières de décision données par un classifieur dans un cas 1D ou 2D, il existe une fonction de la bibliothèque "MLxtend".</p>
<p>Une fois la bibliothèque installée, vous pouvez importer la fonction avec :</p>
<pre><code>from mlxtend.plotting import plot_decision_regions
</code></pre>
<p>Pour afficher les frontières de décision d'une classifieur <code>model</code>, avec les données d'entrainement <code>feature_train</code> et <code>label_train</code>, on utilisera la méthode :</p>
<pre><code>plot_decision_regions(feature_train, label_train, clf=model)
</code></pre>
<p>Pour un problème de dimensionnalité plus élevée que 2, la visualisation des frontières de décision est toujours difficile.</p>
<h4 id="application-a-notre-exemple_1">Application à notre exemple</h4>
<p>Nous allons à présent appliquer les KPPV à notre problème exemple.</p>
<p>Afin de rendre la visualisation plus facile, nous allons simplifier le problème :</p>
<p>Mettons que nous voulons effectuer une classification de nos enregistrements entre les classes "flute", "hautbois" ou "trompette", en utilisant en features l'amplitude relative de la 1ère harmonique et de la 2ème harmonique.</p>
<p>Tout d'abord, nous importons notre fichier CSV sous la forme d'un DataFrame, depuis le chemin <code>input_path</code> :</p>
<pre><code>df_dataset = pd.read_csv(input_path)
</code></pre>
<p>Même si en théorie les KPPV n'ont pas besoin de labels numériques pour fonctionner, certaines des fonctions que nous utiliserons dans la suite ne fonctionnent qu'avec des valeurs numériques.
Nous allons donc encoder les labels "par étiquette" :</p>
<pre><code>from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df_dataset['instrument'] = encoder.fit_transform(df_dataset['instrument'])
</code></pre>
<p>Comme les KPPV se contentent de calculer des distances sur les features, on peut utiliser un encodage par étiquette malgré le fait que nos labels ne sont pas ordinaux.
<strong>Attention :</strong> pour les méthodes utilisant une fonction de coût sur les labels, un encodage "one-hot" devra être utilisé !</p>
<p>Nous récupérons ensuite les features et les labels que nous allons utiliser dans 2 DataFrames :</p>
<pre><code>df_features = df_dataset[['harmo1','harmo2']]
df_labels = df_dataset['instrument']
</code></pre>
<p>Nous séparons ensuite nos données en un jeu d'entrainement (80%) et un jeu de test (20%), sous la forme de 4 DataFrames (2 pour les features, 2 pour les labels) : </p>
<pre><code>from sklearn.model_selection import train_test_split
df_features_train, df_features_test, df_labels_train, df_labels_test = train_test_split(df_features,df_labels,test_size=0.2,random_state=0)
</code></pre>
<p>Enfin, nous réalisons une transformation "centrage-réduction" (voir Chapitre 1), pour s'assurer que les 2 features évoluent sur des intervalles comparables.</p>
<p><strong>Attention ! Il faut calibrer la transformation sur les données d'entrainement, puis l'appliquer aux jeux d'entrainement et de test !</strong></p>
<pre><code>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(df_features_train)

df_features_train[['harmo1','harmo2']] = scaler.transform(df_features_train)
df_features_test[['harmo1','harmo2']] = scaler.transform(df_features_test)
</code></pre>
<p>Maintenant que les données sont prêtes, nous pouvons créer notre classifieur.
Voici comment initialiser un classifieur KPPV avec <span class="arithmatex">\(k=3\)</span> :</p>
<pre><code>from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
</code></pre>
<p>Pour lui fournir les données d'entrainement, comme vu précédemment, il nous suffit d'utiliser la commande suivante :</p>
<pre><code>knn.fit(df_features_train,df_labels_train)
</code></pre>
<p>Nous pouvons à présent utiliser notre modèle pour classifier des données.
Tout d'abord, nous allons évaluer les performances de notre modèle en entrainement et en test.</p>
<p>On peut déjà mesurer l'exactitude de notre classifieur sur ces 2 jeux de données :</p>
<pre><code>print(knn.score(df_features_train,df_labels_train))
print(knn.score(df_features_test,df_labels_test))
</code></pre>
<p>Pour <span class="arithmatex">\(k=3\)</span>, on obtient plus de 99.4% d'exactitude en entrainement, et environ 98.8% d'exactitude en test.</p>
<p>Ces scores laissent à penser que notre modèle aura de plutôt bonnes performances en généralisation. 
Mais n'oublions pas que l'exactitude peut être biaisée en cas de déséquilibre entre classes.
Dans de tels cas, d'autres indicateurs doivent être utilisés.</p>
<p>Voici une matrice de confusion complète pour nous aider à conclure :</p>
<p><img alt="Exemple de matrice de confusion" src="../img/Chap2_exemple_matrice_confusion_2.png" /></p>
<p>On observe qu'à l'entrainement comme en test, le hautbois est très bien séparé des autres instruments, alors que la trompette et la flute sont parfois confondus.
Ce résultat était prévisible au vu de la matrice de nuages de points que nous avions obtenue lors de notre étude préliminaire.
Les proportions d'erreurs restent cependant relativement faibles comparées aux nombres d'observations.</p>
<p>Nous n'avons pour l'instant testé qu'une valeur de <span class="arithmatex">\(k\)</span>.
Pour visualiser l'effet de cet hyperparamètre, nous pouvons utiliser les affichages graphiques de la bibliothèque MLxtend.</p>
<p>Voici les graphiques obtenus pour <span class="arithmatex">\(k=3\)</span> (volontairement faible) et <span class="arithmatex">\(k=31\)</span> (volontairement élevé) :</p>
<p><img alt="Frontières de décision pour notre exemple" src="../img/Chap2_exemple_KPPV_frontieres_decision.png" /></p>
<p>On peut noter que comme attendu, le choix de <span class="arithmatex">\(k\)</span> a le plus d'effet à la frontière entre "flute" et "trompette".
En effet, comme il y a du recouvrement entre ces 2 classes, on sait qu'il vaut mieux choisir un <span class="arithmatex">\(k\)</span> élevé pour éviter le sur-apprentissage.
Ceci est confirmé par le "lissage" de la frontière de décision lorsque l'on utilise <span class="arithmatex">\(k=31\)</span>.</p>
<p>Le choix d'un <span class="arithmatex">\(k\)</span> élevé a donc l'air plus approprié ici, mais il faudrait réaliser une réelle optimisation de cet hyperparamètre.</p>
<p>Par défaut, la distance utilisée par l'implémentation Scikit-Learn des KPPV est la distance Euclidienne.
Nous pouvons également réaliser des affichages pour visualiser l'impact de différentes distances pour une même valeur de <span class="arithmatex">\(k\)</span>.</p>
<p>Voici le résultat pour la distance Euclidienne et la distance de Manhattan, avec <span class="arithmatex">\(k=31\)</span>.</p>
<p><img alt="Frontières de décision pour notre exemple" src="../img/Chap2_exemple_KPPV_frontieres_decision_2.png" /></p>
<p>On observe en effet que le choix de la distance impacte significativement les frontières de décision obtenues, même s'il est difficile ici de juger de la pertinence d'une des 2 distances essayées.
Tout comme pour <span class="arithmatex">\(k\)</span>, il faudrait réaliser une véritable optimisation de cet hyperparamètre.</p>
<h4 id="remarques_1">Remarques</h4>
<p>La méthode des KPPV a les <strong>avantages</strong> suivants :</p>
<ul>
<li>
<p>Il s'agit d'une méthode non-paramétrique, qui ne fait <strong>aucune hypothèse</strong> sur la structure des données.</p>
</li>
<li>
<p>Elle est relativement simple, et n'a <strong>que 2 hyperparamètres</strong> (<span class="arithmatex">\(k\)</span> et la distance), ce qui est peu comparé à certaines méthodes.</p>
</li>
<li>
<p>Si de nouvelles observations doivent être ajoutées au jeu d'entrainement, <strong>la mise à jour du modèle est directe</strong>.</p>
</li>
</ul>
<p>Mais cette méthode a aussi les <strong>limites</strong> suivantes :</p>
<ul>
<li>
<p>Le modèle ayant besoin de stocker les données d'entrainement, il peut vite devenir <strong>très lourd</strong>.</p>
</li>
<li>
<p>Elle fonctionne mal avec des données de <strong>grande dimension</strong>.</p>
</li>
<li>
<p>Elle est très sujette au <strong>sur-apprentissage</strong>.</p>
</li>
</ul>
<h3 id="perceptron-multicouche">Perceptron multicouche</h3>
<p>La méthode de classification que nous allons voir à présent est une ouverture vers les <strong>réseaux de neurones artificiels</strong>, et la discipline qui leur est associée : l'<strong>apprentissag profond</strong> (ou "Deep Learning" en anglais).</p>
<h4 id="perceptron-un-neurone-artificiel">Perceptron : un neurone artificiel</h4>
<p>Lorsque l'on parle d'apprentissage pour un humain, on pense tout de suite à son cerveau, et plus particulièrement à ses <strong>neurones</strong>.</p>
<p>Un neurone est en effet une <strong>machine à apprendre</strong> : </p>
<p>Il prend plusieurs signaux électriques en entrée, donne plus ou moins d'importance à chacun, et transmet ou non un signal électrique en sortie en fonction de ces entrées pondérées avec un seuil.
Le neurone apprendra les poids à donner à chaque entrée pour fournir une sortie pertinente pour une application.</p>
<p>Un neurone se comporte donc comme un <strong>classifieur binaire</strong>.
D'où l'idée séduisante de s'inspirer des neurones pour l'apprentissage de ce type de modèle.</p>
<p>Le 1er modèle mathématique d'un neurone, appelé "neurone formel" ou "neurone artificiel", est proposé par McCulloch et Pitts en 1943.
Dans le cadre de l'apprentissage automatique, il est plus connu sous le nom de "<strong>perceptron</strong>", concept inventé par Rosenblatt en 1957.</p>
<p>Voici le principe du perceptron "historique" de 1957 :</p>
<p><img alt="Perceptron" src="../img/Chap2_perceptron.png" /></p>
<ul>
<li>
<p>Les <span class="arithmatex">\(p\)</span> réalisations de nos <span class="arithmatex">\(p\)</span> features correspondant à un individu sont fournies comme <span class="arithmatex">\(p\)</span> <strong>entrées</strong> à notre neurone.
Une entrée supplémentaire toujours fixée à 1 sera également fournie, on la nommera "<strong>biais</strong>".</p>
</li>
<li>
<p>On applique à chaque entrée <span class="arithmatex">\(x_i\)</span> un coefficient <span class="arithmatex">\(w_i\)</span>.
C'est ce que l'on appellera les <strong>paramètres</strong> du modèle.</p>
</li>
<li>
<p>Toutes les entrées <span class="arithmatex">\(x_i\)</span> pondérées par <span class="arithmatex">\(w_i\)</span> sont <strong>sommées</strong>, donnant la combinaison <strong>linéaire</strong> <span class="arithmatex">\(w_0 + w_1 x_1 + w_2 x_2 + ... + w_p x_p\)</span>.</p>
</li>
<li>
<p>Un <strong>seuil</strong> est finalement appliqué à cette somme : suivant si elle dépasse ou non une certaine valeur, la <strong>sortie</strong> sera soit 0 ou 1, soit -1 ou 1 suivant la fonction de seuil choisie.</p>
</li>
</ul>
<p>L'apprentissage de ce modèle consistera en l'<strong>optimisation des paramètres</strong>, afin qu'à partir des features il soit capable d'associer ou non l'individu à une classe (0 ou 1 en sortie).</p>
<p>On utilisera le processus d'entrainement suivant :</p>
<ul>
<li>
<p>On initialise les paramètres aléatoirement.</p>
</li>
<li>
<p>On fait passer un à un les individus du jeu d'entrainement à travers le modèle.</p>
</li>
<li>
<p>Pour chaque individu on compare la sortie du modèle à celle attendue, et on met à jour les paramètres en conséquence.</p>
</li>
<li>
<p>On repète les 2 étapes précédentes jusqu'à convergence.</p>
</li>
</ul>
<p>On appelle la fonction apprise <span class="arithmatex">\(f(x_1,x_2,...,x_p) = w_0 + w_1 x_1 + w_2 x_2 + ... + w_p x_p\)</span> la <strong>fonction discriminante</strong>.</p>
<p>Comme cette fonction est linéaire, le modèle ne pourra établir que des <strong>frontières de décision linéaires</strong> (un point en 1D, une droite en 2D, un plan en 3D, un hyperplan dans le cas général).</p>
<p>Nous verrons que ceci est assez limitant en pratique : <strong>tous les problèmes ne sont pas linéairement séparables !</strong></p>
<p>Voici une représentation schématique d'une frontière de décision 2D :</p>
<p><img alt="Frontière de décision d'un perceptron 2D" src="../img/Chap2_perceptron_frontiere_decision.png" /></p>
<p>Comme nous l'avons expliqué précédemment, on peut réaliser de la classification multi-classe à partir de plusieurs classifieurs binaires, avec une stratégie One-versus-All ou One-Versus-One.
Pour un perceptron, il suffira donc d'utiliser <strong>plusieurs neurones en parallèle</strong> avec les mêmes entrées.</p>
<p>Voici un exemple de <span class="arithmatex">\(n\)</span> perceptrons <span class="arithmatex">\(N\)</span> en parallèle pour <span class="arithmatex">\(n\)</span> classes :</p>
<p><img alt="Perceptron multi-classe" src="../img/Chap2_perceptron_multiclasse.png" /></p>
<p>Pour pouvoir entrainer un perceptron, il reste à choisir une méthode pour <strong>mettre à jour les paramètres</strong> du modèle à partir des erreurs de prédiction.</p>
<p>La "règle d'apprentissage du perceptron" proposée par Rosenblatt est la suivante.
A l'itération <span class="arithmatex">\(k\)</span>, pour le <span class="arithmatex">\(i\)</span>-ème paramètre, on applique :</p>
<p><span class="arithmatex">\(w_i^{(k+1)} = w_i^{(k)} - \gamma (y^{(k)}-\hat{y}^{(k)})\)</span></p>
<p>avec <span class="arithmatex">\(y\)</span> la sortie attendue, et <span class="arithmatex">\(\hat{y}\)</span> la prédiction.</p>
<p>On reconnait une méthode type <strong>descente de gradient</strong> (voir Chapitre 1), mais très simple.</p>
<p>Ici, on ne calcule pas le gradient de la fonction de coût à partir de la totalité du jeu d'entrainement, mais à partir d'un seul individu.
Ce qui rend cet algorithme d'optimisation rapide, mais aussi sensible aux minima locaux.</p>
<p>Néanmoins, on peut montrer que <strong>si les classes sont linéairement séparables</strong> alors la méthode <strong>convergence forcément</strong>.
C'est le "théorème de convergence du perceptron".</p>
<p>Par contre, dans les cas <strong>non-linéairement séparables</strong>, cette méthode <strong>ne donnera pas de résultats satisfaisants</strong>.</p>
<h4 id="perceptron-multicouche-un-reseau-de-neurones-artificiels">Perceptron multicouche : un réseau de neurones artificiels</h4>
<p>Le perceptron est une 1ère approche simple à mettre en place et à entrainer.
Mais il n'est applicable en pratique que pour les problèmes linéairement séparables.</p>
<p>C'est pourquoi dans les années 1960, a émergé l'idée de relier plusieurs perceptron en sens direct.
On appellera ce type de <strong>réseau de neurones</strong> un <strong>perceptron multicouche</strong> (PMC).</p>
<p>L'idée est la suivante : si une combinaison linéaire avec un seuil ne peut produire que des frontières de décisions linéaires, une combinaison de séparateurs linéaires avec chacun un seuil peut donner un <strong>séparateur non-linéaire</strong>. </p>
<p>Le PMC le plus basique possède <strong>3 couches</strong> totalement connectées :</p>
<p><img alt="Perceptron multicouche" src="../img/Chap2_perceptron_multicouche.png" /></p>
<ul>
<li>
<p>La <strong>couche d'entrée</strong> : il s'agit simplement des différentes features d'entrée du modèle.</p>
</li>
<li>
<p>La <strong>couche cachée</strong> : une couche de neurones (perceptrons), chacun ayant ses paramètres, son biais, son seuil.
Elle est "cachée" car ses sorties sont invisibles pour l'utilisateur.</p>
</li>
<li>
<p>La <strong>couche de sortie</strong> : une couche de neurone en fin de réseau, chacun ayant ses paramètres, son biais, son seuil, qui va renvoyer la sortie du modèle pour chaque classe.</p>
</li>
</ul>
<p>On peut démontrer que ce modèle est capable de tracer <strong>n'importe quelle frontière de décision</strong>, à condition d'avoir assez de neurones dans la couche cachée.
C'est ce que l'on appelle le <strong>théorème de l'approximation universelle</strong>.</p>
<p>Le problème est que plus la frontière de décision à tracer est complexe, et plus il faut de neurones dans la couche limite.</p>
<p>Pour résoudre ce problème, on peut ajouter plusieurs couches cachées entre les couches d'entrée et de sortie : pour un nombre de neurones par couche donné, plus on aura de couches, et plus complexes les frontières de décisions pourront être.
Dès que l'on a plus d'une couche cachée, on parle d'<strong>apprentissage profond</strong> ("Deep Learning").</p>
<p>Nous comprenons bien le potentiel du PMC... à condition de pouvoir l'entrainer !</p>
<p>En effet, comment réussir à optimiser efficacement les paramètres de nos différentes couches, sachant que les couches sont totalement connectées ?</p>
<p>Ce problème est resté un point de blocage jusqu'en 1985, grâce aux travaux de Rumlhart et son équipe.
La méthode qu'ils ont proposée pour entrainer un PMC, encore utilisée aujourd'hui, est connue sous le nom de <strong>rétropropagation du gradient</strong>.</p>
<h4 id="retropropagation-du-gradient">Retropropagation du gradient</h4>
<p>Voici le principe sur lequel fonctionne l'algorithme de la propagation du gradient :</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Algorithme de retropropagation du gradient</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Les paramètres du modèle sont initialisés aléatoirement.</td>
</tr>
<tr>
<td style="text-align: left;">A chaque itération (époque) de l'algorithme :</td>
</tr>
<tr>
<td style="text-align: left;">- Un échantillon d'individus est sélectionné.</td>
</tr>
<tr>
<td style="text-align: left;">- <strong>Passage direct</strong> : cet échantillon est fourni en entrée du modèle, et la sortie est récupérée.</td>
</tr>
<tr>
<td style="text-align: left;">- Une <strong>fonction de coût</strong> est utilisée pour évaluer l'erreur entre la sortie du modèle et ce qui était attendu.</td>
</tr>
<tr>
<td style="text-align: left;">- <strong>Passage inverse</strong> : le gradient de l'erreur associée à chaque paramètre est calculé en évaluant la contribution de chaque paramètre à l'erreur, en allant de la sortie vers l'entrée.</td>
</tr>
<tr>
<td style="text-align: left;">- Ces gradients sont fournis à l'algorithme de <strong>descente de gradient</strong> (voir Chapitre 1), qui va mettre à jour les paramètres du modèle.</td>
</tr>
</tbody>
</table>
<p>On en déduit que plus le nombre de couches cachée et de neurones par couche cachée sera élevé, plus l'apprentissage sera long.
Aussi, un nombre de couches trop élevé peut rendre difficile l'apprentissage des couches les plus en amont : un phénomène connu sous le nom de "problème de la disparition du grandient".</p>
<p>Pour que cet algorithme fonctionne avec le PMC, il a fallu modifier la fonction de sortie des neurones.</p>
<p>En effet, la fonction "seuil" ne permet pas de calculer un gradient : elle a un problème de différentiabilité, et une pente nulle partout sauf en un point.</p>
<p>C'est pourquoi d'autres "<strong>fonctions d'activation</strong>" sont utilisées en sortie des neurones d'un PMC.</p>
<p>On peut citer les 3 plus utilisées :</p>
<ul>
<li><strong>Sigmoïde</strong> : <span class="arithmatex">\(g(u) = \frac{1}{1+exp(-u)}\)</span></li>
</ul>
<p>Il s'agit de la fonction historique, directement inspirée de la fonction d'activation d'un neurone biologique.
Elle a l'avantage d'être continue et à dérivée non nulle partout.
Elle retourne un score entre 0 et 1.</p>
<ul>
<li><strong>Tangente hyperbolique</strong> : <span class="arithmatex">\(g(u) = tanh(u)\)</span></li>
</ul>
<p>Tout comme la sigmoïde, elle a une forme proche de la fonction d'activation d'un neurone biologique.
Elle est également continue et à dérivée non nulle partout.
Elle retourne un score entre -1 et 1.</p>
<ul>
<li><strong>ReLU</strong> : <span class="arithmatex">\(g(u) = max(0,u)\)</span>
Très utilisée depuis les années 2010, cette fonction n'a aucune inspiration biologique.
Elle a un problème de dérivabilité en 0, et elle ne retourne pas un score borné.
Par contre, elle permet de lutter contre les problème de "disparition du gradient".</li>
</ul>
<p>Lorsque l'on veut résoudre un problème de classification multi-classe (mais pas multi-sorties) avec un PMC, au lieu d'une approche One-versus-All ou One-versus-One, on peut utiliser la fonction d'activation suivante :</p>
<ul>
<li><strong>Softmax</strong> : pour chaque neurone de sortie <span class="arithmatex">\(i\)</span> on calcule <span class="arithmatex">\(g(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{n} e^{y_j}}\)</span> et on retient la classe correspondant à la sortie maximisant cette fonction.</li>
</ul>
<p>L'idée est que cette fonction prend en entrée les scores renvoyés par chaque neurone de sortie, et les transforme en probabilité d'appartenance à chaque classe (la somme donnant 1).</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Nota Bene</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Pour que l'apprentissage d'un perceptron ou d'un PMC se déroule correctement, il est recommandé d'effectuer une <strong>transformation des données</strong> d'entrée (voir Chapitre 1), afin d'éviter que le modèle donne artificiellement plus de poids à une feature juste parce qu'elle varie sur une plus grande plage de valeurs.</td>
</tr>
</tbody>
</table>
<h4 id="choix-des-hyperparametres">Choix des hyperparamètres</h4>
<p>Une des difficulté de l'apprentissage d'un PMC est le nombre élevé de paramètres et d'hyperparamètres à optimiser.
Ceci rend le PMC particulièrement <strong>sensible au sur-apprentissage</strong>.</p>
<p>Une stratégie de validation par exclusion ou de validation croisée est donc plus que recommandée !</p>
<p>Parmi les <strong>hyperparamètres</strong> à optimiser, on peut citer :</p>
<ul>
<li>
<p>Le nombre de couches cachées.</p>
</li>
<li>
<p>Le nombre de neurones par couche cachée.</p>
</li>
<li>
<p>La fenêtre d'activation pour les couches cachées.</p>
</li>
<li>
<p>La fenêtre d'activation pour la couche de sortie.</p>
</li>
<li>
<p>Le taux d'apprentissage pour la descente de gradient.</p>
</li>
<li>
<p>Le nombre maximum d'époques d'apprentissage, et pratiquer ou non de l'arrêt prématuré.</p>
</li>
<li>
<p>La fonction de coût utilisée pour l'apprentissage.</p>
</li>
</ul>
<p>De plus, l'initialisation des paramètre du modèle se faisant de manière aléatoire, 2 apprentissages ne donneront pas le même modèle.
Il convient donc de tester plusieurs initialisations.</p>
<h4 id="implementation-scikit-learn_2">Implémentation Scikit-Learn</h4>
<p>Il existe une implémentation Scikit-Learn du PMC pour la classification.</p>
<p>Elle peut être importée avec :</p>
<pre><code>from sklearn.neural_network import MLPClassifier
</code></pre>
<p>On peut ensuite initialiser un classifieur PMC <code>mlp</code> avec les hyperparamètres par défaut en utilisant la commande :</p>
<pre><code>mlp = MLPClassifier()
</code></pre>
<p>Nous verrons plus loin quels sont ces hyperparamètres.</p>
<p>Pour donner le jeu d'entrainement (features avec <code>feature_train</code> et labels avec <code>label_train</code>) à ce classifieur, on utilise la méthode :</p>
<pre><code>mlp.fit(feature_train,label_train)
</code></pre>
<p>On peut à présent réaliser des prédictions <code>label_test</code> à partir de features de test <code>feature_test</code> :</p>
<pre><code>label_test = mlp.predict(feature_test)
</code></pre>
<p>Si on veut effectuer un test de notre classifieur sur un jeu de données labéliser, on peut obtenir un score d'exactitude avec la commande :</p>
<pre><code>mlp.score(feature_test,label_test)
</code></pre>
<p>Voici les hyperparamètres par défaut de l'implémentation Scikit-Learn du PMC :</p>
<ul>
<li>
<p>Nombre de couches cachées : 1</p>
</li>
<li>
<p>Nombre de neurones par couche cachée : 100</p>
</li>
<li>
<p>La fenêtre d'activation pour les couches cachées : ReLU</p>
</li>
<li>
<p>La fenêtre d'activation pour la couche de sortie : Sigmoïde si binaire, Softmax si multi-classe (non modifiable)</p>
</li>
<li>
<p>Le taux d'apprentissage pour la descente de gradient : 0.001</p>
</li>
<li>
<p>Le nombre maximum d'époques d'apprentissage : 200 (par défaut sans arrêt prématuré, mais on peut l'activer)</p>
</li>
<li>
<p>La fonction de coût : Log-loss (non modifiable)</p>
</li>
</ul>
<p>Ces hyperparamètres sont presque tous modifiables par l'utilisateur.</p>
<h4 id="application-a-notre-exemple_2">Application à notre exemple</h4>
<p>Nous allons à présent appliquer le PMC par défaut de Scikit-Learn à notre problème exemple.</p>
<p>Cette fois-ci, nous n'allons pas simplifier notre exemple : nous traiterons directement le problème 3D.</p>
<p>Comme pour les exemples précédents, nous importons notre fichier CSV sous la forme d'un DataFrame, depuis le chemin <code>input_path</code> :</p>
<pre><code>df_dataset = pd.read_csv(input_path)
</code></pre>
<p>Nous allons ensuite encoder les labels "par étiquette" :</p>
<pre><code>from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df_dataset['instrument'] = encoder.fit_transform(df_dataset['instrument'])
</code></pre>
<p>Ce choix peut paraitre étonnant, puisque nos labels ne sont pas ordinaux.
On aurait plutôt tendance à utiliser de l'encodage "one-hot".</p>
<p>L'astuce est que l'implémentation "MLPClassifier" de Scikit-Learn réalise implicitement un encodage "one-hot" à partir de labels "par étiquette".</p>
<p>Nous récupérons ensuite les features et les labels que nous allons utiliser dans 2 DataFrames :</p>
<pre><code>df_features = df_dataset[['harmo1','harmo2','harmo3']]
df_labels = df_dataset['instrument']
</code></pre>
<p>Nous séparons ensuite nos données en un jeu d'entrainement (80%) et un jeu de test (20%), sous la forme de 4 DataFrames (2 pour les features, 2 pour les labels) : </p>
<pre><code>from sklearn.model_selection import train_test_split
df_features_train, df_features_test, df_labels_train, df_labels_test = train_test_split(df_features,df_labels,test_size=0.2,random_state=0)
</code></pre>
<p>Afin d'aider le PMC à converger, nous allons effectuer une transformation centrage-réduction (voir Chapitre 1) afin de s'assurer que les 3 features évoluent sur des intervalles comparables.</p>
<p><strong>Attention ! Il faut calibrer la transformation sur les données d'entrainement, puis l'appliquer aux jeux d'entrainement et de test !</strong></p>
<pre><code>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(df_features_train)

df_features_train[['harmo1','harmo2','harmo3']] = scaler.transform(df_features_train)
df_features_test[['harmo1','harmo2','harmo3']] = scaler.transform(df_features_test)
</code></pre>
<p>Maintenant que les données sont prêtes, nous pouvons créer notre classifieur.
Voici comment initialiser un classifieur PMC avec les paramètres par défaut :</p>
<pre><code>from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier()
</code></pre>
<p>Pour l'entrainer, il nous suffit d'utiliser la commande suivante :</p>
<pre><code>mlp.fit(df_features_train,df_labels_train)
</code></pre>
<p>Nous pouvons à présent utiliser notre modèle pour classifier des données.
Tout d'abord, nous allons évaluer les performances de notre modèle en entrainement et en test.</p>
<p>On peut déjà mesurer l'exactitude de notre classifieur sur ces 2 jeux de données :</p>
<pre><code>print(mlp.score(df_features_train,df_labels_train))
print(mlp.score(df_features_test,df_labels_test))
</code></pre>
<p>On obtient facilement plus de 99% d'exactitude en entrainement, et plus de 98.5% d'exactitude en test.
Ces résultats laissent à pense que les performances en généralisation de notre modèle seront plutôt bonnes.</p>
<p>Mais comme nous l'avons fait remarquer plus tôt, le PMC est sensible au sur-apprentissage.
Pour cette raison, on peut vouloir appliquer la méthode de régularisation par "arrêt prématuré" (voir Chapitre 1).</p>
<p>Si on active le paramètre <code>early_stopping</code> du classifieur PMC de Scikit-Learn, au moment de l'apprentissage il va automatiquement mettre de côté une partie du jeu d'entrainement pour faire un jeu de validation.
On peut même choisir la fraction du jeu d'entrainement à utiliser pour la validation, avec le paramètre <code>validation_fraction</code>.</p>
<p>Voici un exemple de définition d'un classifieur, avec de l'arrêt prématuré et 20% des données d'entrainement utilisées pour la validation :</p>
<pre><code>mlp = MLPClassifier(early_stopping=True,validation_fraction=0.2)
</code></pre>
<p>Il y a aussi une astuce pour afficher l'évaluation de la fonction de coût au cours des époques, pour l'ensemble d'entrainement et de validation.
Elle se base sur :</p>
<ul>
<li>
<p>Extraire le jeu de validation avec la méthode <code>train_test_split</code> de Scikit-Learn.</p>
</li>
<li>
<p>Utiliser la méthode <code>partial_fit</code> de notre classifieur PMC, qui permet de réaliser une itération à la fois.</p>
</li>
<li>
<p>Récupérer la valeur de la fonction de coût sur le jeu d'entrainement, avec l'attribut <code>loss_</code> de notre classifieur.</p>
</li>
<li>
<p>Evaluer la valeur de la fonction de coût sur le jeu de validation, en utilisant la fonction <code>log_loss</code> de Scikit-Learn.</p>
</li>
</ul>
<p>Voici l'affichage des 2 courbes Matplotlib obtenues sur notre base de données, pour 50 époques :</p>
<pre><code>import matplotlib.pyplot as plt
from sklearn.metrics import log_loss

df_features_train, df_features_validation, df_labels_train, df_labels_validation = train_test_split(df_features_train,df_labels_train,test_size=0.2,random_state=0)

mlp = MLPClassifier()

loss_train = []
loss_validation = []

for idx in range(50):
    mlp.partial_fit(df_features_train,df_labels_train,classes=[0,1,2])
    loss_train.append(mlp.loss_)
    loss_validation.append(log_loss(df_labels_validation,mlp.predict_proba(df_features_validation)))

plt.plot(loss_train, label=&quot;train loss&quot;,c='r')
plt.plot(loss_validation, label=&quot;validation loss&quot;,c='g')
plt.xlabel('Epoques')
plt.ylabel('Fonction de coût')
plt.legend()
</code></pre>
<p>Les performances obtenues avec ce modèle sont déjà excellentes, mais <strong>il faudrait à présent se baser sur ces codes pour effectuer une optimisation des hyperparamètres.</strong></p>
<h4 id="remarques_2">Remarques</h4>
<p>La méthode du Perceptron Multi-Couche a les <strong>avantages</strong> suivants :</p>
<ul>
<li>
<p>Elle permet de dessiner des <strong>frontières de décision complexes</strong> entre les classes sans faire de grosses hypothèses statistiques au préalable.</p>
</li>
<li>
<p>Une fois le modèle entrainé, il prend <strong>moins de mémoire</strong> et est <strong>plus rapide</strong> pour faire des prédiction que les KPPV.</p>
</li>
<li>
<p>On peut entrainer ce type de modèle sur de <strong>très grandes bases de données</strong>.</p>
</li>
</ul>
<p>Mais cette méthode a aussi les <strong>limites</strong> suivantes :</p>
<ul>
<li>
<p>Elle a de <strong>nombreux paramètres et hyperparamètres</strong> à optimiser.</p>
</li>
<li>
<p>Elle est <strong>sensible au sur-apprentissage</strong>.</p>
</li>
<li>
<p>Les décisions qu'elle prend sont <strong>difficilement expliquées</strong> et <strong>interprétables</strong> : il est difficile voir impossible pour un humain de les comprendre.
On parle de "boîte noire".</p>
</li>
<li>
<p>L'initialisation de la méthode se faisant de manière <strong>aléatoire</strong>, 2 apprentissages ne donneront pas exactement le même modèle.</p>
</li>
</ul>
<p>Les réseaux de neurones sont à la base des modèles d'apprentissage modernes, fondant ainsi une nouvelle sous-discipline : l'<strong>apprentissage profond</strong>.</p>
<p><strong>Nous verrons dans le chapitre suivant que le PMC peut aussi être utilisé pour résoudre des problèmes de régression...</strong></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../Chap1_Introduction/" class="btn btn-neutral float-left" title="I. Introduction"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../Chap3_Regression/" class="btn btn-neutral float-right" title="III. Régression">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../Chap1_Introduction/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../Chap3_Regression/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../javascripts/mathjax.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
